---
title: FM和FFM算法精髓
date: 2018-03-13 15:26:27
tags: Algorithm
categories: Machine Learning
---

FM和FFM在CTR预估上有着非常不错的效果，[美团的文章](https://tech.meituan.com/deep-understanding-of-ffm-principles-and-practices.html)，讲的十分详细了，这里简明扼要的记录一下理解的过程，以及两种算法的重点。

FM解决的问题，如帖子中所说，是特征在one-hot编码后的稀疏问题，那么稀疏会导致什么问题？就是训练模型系数的时候少了不少样本。那么FM借鉴了矩阵分解的方式，将所有不为0的系数Wij组合成一个对称矩阵，然后将其拆分。拆分的意义在于，将原来的高维系数矩阵分解成由众多低维矩阵隐向量相乘的结果，而每一个隐向量vi，可以由包含xi样本且不为0的关联特征样本训练而得，亦即vi这个低维隐向量就有充分的训练集，这就充分利用了系数矩阵中不为0的样本。举例说明：就xi和xj而言，二项式情况下我们如果想训练系数Wij，就需要大量的xi != 0 || xj != 0的样本，而当拆分成<vi, vj>后，当我们想训练vi，我们只需要保证xi != 0即可。

FFM解决的问题，是在FM的基础上，增加Field的概念。说白了，就是将几个Field进行组合后，再在组合而成的Field的基础之上进行FM，实际上是增加了训练样本，使得结果更精确，但是它的训练时间比较尴尬：O(kn^2)，而FM是线性的：O(kn)

从数学的角度，可以更加细致的去理解，参考下面两幅图：

![高山仰止](https://raw.githubusercontent.com/Hunglish/Blog-Photos/master/picture/20180313FM01.jpg)

![高山仰止](https://raw.githubusercontent.com/Hunglish/Blog-Photos/master/picture/20180313FM02.jpg)

由于时间关系，算法的实现和应用我这里就不赘述，有空再补。具体可以参考上面帖子链接，讲解的非常好。