---
title: Hadoop配置总结
date: 2018-03-11 18:11:12
tags: Hadoop
categories: Coding
---

下载hadoop后，需要配置一下地方。

#### JDK1.7及以上的版本

#### 配置SSH无密码登录 

$ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa

$ cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys

这一点很重要，在单机模式启动守护进程的时候，需要本地回环ping通才可以。否则守护进程启动也不成功。

#### 安装hadoop

环境变量不用多说了 千篇一律都是bin文件夹

主要的就是配置以下几个文件：

- hadoop-2.7.1/etc/hadoop/hadoop-env.sh 
- hadoop-2.7.1/etc/hadoop/yarn-env.sh 
- hadoop-2.7.1/etc/hadoop/core-site.xml 
- hadoop-2.7.1/etc/hadoop/hdfs-site.xml 
- hadoop-2.7.1/etc/hadoop/mapred-site.xml 
- hadoop-2.7.1/etc/hadoop/yarn-site.xml

##### 配置hadoop-env.sh

主要就是配置JAVA_HOME

##### 配置yarn-env.sh

这个也是JAVA_HOME

#####  配置core-site.xml

```
<configuration>
 <property>
    <name>fs.default.name</name>
    <value>hdfs://localhost:9000</value>
    <description>HDFS的URI，文件系统://namenode标识:端口号</description>
</property>

<property>
    <name>hadoop.tmp.dir</name>
    <value>/usr/hadoop/tmp</value>
    <description>namenode上本地的hadoop临时文件夹</description>
</property>
</configuration>
```
##### 配置hdfs-site.xml

```
<configuration>
<!—hdfs-site.xml-->
<property>
    <name>dfs.name.dir</name>
    <value>/usr/hadoop/hdfs/name</value>
    <description>namenode上存储hdfs名字空间元数据 </description> 
</property>

<property>
    <name>dfs.data.dir</name>
    <value>/usr/hadoop/hdfs/data</value>
    <description>datanode上数据块的物理存储位置</description>
</property>

<property>
    <name>dfs.replication</name>
    <value>1</value>
    <description>副本个数，配置默认是3,应小于datanode机器数量</description>
</property>
</configuration>
```

##### hadoop启动

* 格式化namenode： bin/hdfs namenode -format
* 启动namenode和datanode的守护进程: sbin/start-dfs
* 启动ResouceManager和Nodemanager: sbin/start-yarn.sh

##### 启动验证

jps命令下如下进程说明启动成功：

```
# jps
6097 NodeManager
11044 Jps
7497 -- process information unavailable
8256 Worker
5999 ResourceManager
5122 SecondaryNameNode
8106 Master
4836 NameNode
4957 DataNode
```